{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NewsAPI Classification and Text Analysis\n",
        "Authors: Christian Lee, Anahit Shekikyan, Graham Ward "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function Creations\n",
        "\n",
        "Please use this section to develop functions or place them here from previous assignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function creations\n",
        "\n",
        "# Functions from previous assignments before cell\n",
        "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
        "    \"\"\"\n",
        "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
        "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
        "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
        "        of unique tokens, lexical diversity, and number of characters. \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    # Fill in the correct values here. \n",
        "    total_tokens = len(tokens)\n",
        "    num_unique_tokens = len(set(tokens))\n",
        "    lexical_diversity = num_unique_tokens / total_tokens if total_tokens > 0 else 0\n",
        "    num_characters = sum(len(token) for token in tokens)\n",
        "    \n",
        "    if verbose :        \n",
        "        print(f\"There are {total_tokens} tokens in the data.\")\n",
        "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
        "        print(f\"There are {num_characters} characters in the data.\")\n",
        "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
        "    \n",
        "        # print the five most common tokens\n",
        "        token_counts = Counter(tokens)\n",
        "        print(f\"The {num_tokens} most common tokens are:\")\n",
        "        for token, count in token_counts.most_common(num_tokens):\n",
        "            print(f\" {token}: {count}\")\n",
        "                    \n",
        "    return([total_tokens, num_unique_tokens,\n",
        "            lexical_diversity,\n",
        "            num_characters])\n",
        "\n",
        "# construct function for cleaning and tokenizing\n",
        "def clean_and_tokenize(text, stopwords):\n",
        "    \"\"\"\n",
        "    Clean and tokenize a single speech from the conventions.\n",
        "\n",
        "    This function applies the following steps:\n",
        "      1. Converts all characters to lowercase.\n",
        "      2. Removes punctuation characters by replacing them with spaces.\n",
        "      3. Collapses multiple whitespace characters into a single space and strips leading/trailing spaces.\n",
        "      4. Splits the cleaned string into tokens on whitespace.\n",
        "      5. Removes any tokens that are in the provided stopword set.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        A single text of a speech to clean and tokenize.\n",
        "    stopwords : set\n",
        "        A set of stopwords (all lowercase) to filter out from the resulting tokens.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list of str\n",
        "        A list of cleaned tokens with punctuation removed, normalized case, and stopwords excluded.\n",
        "    \"\"\"\n",
        "    # handle coercion to string format error handling\n",
        "    if text is None:\n",
        "        return []\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    # make lowercase\n",
        "    text = text.lower()\n",
        "    # punctuation removal\n",
        "    text = \"\".join(ch if ch not in punctuation else \" \" for ch in text)\n",
        "    # replace whitespace with single whitespace and remove leading/trailing ws\n",
        "    text = ws_pattern.sub(\" \", text).strip()\n",
        "    # handle nulls\n",
        "    if not text:\n",
        "        return []\n",
        "    # split cleaned string on space\n",
        "    tokens = text.split()\n",
        "    # remove stopwords\n",
        "    return [t for t in tokens if t not in stopwords]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EDu-CYTgbP9T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   category                                              title  \\\n",
            "0  business  Hasbro leaving Pawtucket for Boston, bringing ...   \n",
            "1  business  Meta suppressed children’s safety research, fo...   \n",
            "2  business  PNC to buy FirstBank for $4.1B, expanding to A...   \n",
            "3  business  Mortgage rates dive on reports of worsening ec...   \n",
            "4  business  US Steel is shutting down a mill in Illinois. ...   \n",
            "\n",
            "                                         description  \\\n",
            "0  Hasbro, the century-old company behind childho...   \n",
            "1  Four whistleblowers share documents with Congr...   \n",
            "2  PNC Financial plans to buy Colorado-based Firs...   \n",
            "3  One housing economist says the 30-year mortgag...   \n",
            "4  US Steel will stop producing steel at its Gran...   \n",
            "\n",
            "                                             content  content_len  \n",
            "0  BOSTON —Hasbro, the century-old company behind...          200  \n",
            "1  Two current and two former Meta employees disc...          200  \n",
            "2  NEW YORK (AP) PNC Financial said Monday that i...          200  \n",
            "3  Mortgage rates are taking a deep dive as finan...          200  \n",
            "4  US Steel is shuttering production at a mill in...          200  \n"
          ]
        }
      ],
      "source": [
        "# import the articles csv into a pandas dataframe for manipulation\n",
        "df = pd.read_csv('articles.csv')\n",
        "\n",
        "# print the head of the dataframe\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Descriptive Stats and Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['category', 'title', 'description', 'content', 'content_len'], dtype='object')\n",
            "\n",
            " category       object\n",
            "title          object\n",
            "description    object\n",
            "content        object\n",
            "content_len     int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# print out the unique colummns of the dataframe\n",
        "print(df.columns)\n",
        "# print the data types of each column\n",
        "print(\"\\n\", df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of rows in the dataframe are:  4131\n"
          ]
        }
      ],
      "source": [
        "# print the number of rows in the dataframe\n",
        "print(\"The number of rows in the dataframe are: \", df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get counts for each category\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Splitting and Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Development (Training, Validation and Testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ads509",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
